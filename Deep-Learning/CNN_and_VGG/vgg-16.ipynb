{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"1tcA9HZ4SPTEmQWIPhRjBlrZZYvTJ9WyV","timestamp":1744230750429}],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11257125,"sourceType":"datasetVersion","datasetId":7035322}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"56b6bb68","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport os\ntorch.set_num_threads(os.cpu_count())\nfrom torch import optim as optim\nfrom torch import nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport torchvision\nimport torchvision.transforms as transforms\nimport random\nnp.random.seed(0)\ntorch.manual_seed(0)\nrandom.seed(0)\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","metadata":{"id":"56b6bb68","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:49:39.995872Z","iopub.execute_input":"2025-04-09T21:49:39.996176Z","iopub.status.idle":"2025-04-09T21:49:46.738295Z","shell.execute_reply.started":"2025-04-09T21:49:39.996152Z","shell.execute_reply":"2025-04-09T21:49:46.737438Z"}},"outputs":[],"execution_count":1},{"id":"8914f5bf-f746-424f-9111-55a4805d9a01","cell_type":"markdown","source":"Reference: https://www.kaggle.com/code/blurredmachine/vggnet-16-architecture-a-complete-guide","metadata":{}},{"id":"5301e217-b6a9-4520-b69f-3c34ee066196","cell_type":"code","source":"data_folder = os.listdir(\"/kaggle/input/arsl-256\")\nnum_classes = data_folder.__len__()\nprint(num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:49:51.152479Z","iopub.execute_input":"2025-04-09T21:49:51.152932Z","iopub.status.idle":"2025-04-09T21:49:51.166261Z","shell.execute_reply.started":"2025-04-09T21:49:51.152902Z","shell.execute_reply":"2025-04-09T21:49:51.165475Z"}},"outputs":[{"name":"stdout","text":"31\n","output_type":"stream"}],"execution_count":2},{"id":"5d0eec65","cell_type":"code","source":"import torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\n\nclass ASLDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.classes = os.listdir(data_dir)\n        self.image_paths = []\n        self.labels = []\n        for i, class_name in enumerate(self.classes):\n            class_dir = os.path.join(data_dir, class_name)\n            for image_name in os.listdir(class_dir):\n                image_path = os.path.join(class_dir, image_name)\n                self.image_paths.append(image_path)\n                self.labels.append(i)  # Use the class index as the label\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ndataset = ASLDataset(\"/kaggle/input/arsl-256\", transform=transform)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5d0eec65","executionInfo":{"status":"ok","timestamp":1744230052451,"user_tz":-120,"elapsed":6721,"user":{"displayName":"Hossam Eldin Abdelrazek","userId":"16974979097625293558"}},"outputId":"ee77357c-8244-4bf2-b279-858404d61c2d","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:50:32.145142Z","iopub.execute_input":"2025-04-09T21:50:32.145439Z","iopub.status.idle":"2025-04-09T21:50:32.179675Z","shell.execute_reply.started":"2025-04-09T21:50:32.145417Z","shell.execute_reply":"2025-04-09T21:50:32.178773Z"}},"outputs":[],"execution_count":12},{"id":"ffcb3d07-a12c-4164-a99d-2617c0c558cc","cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:50:33.488476Z","iopub.execute_input":"2025-04-09T21:50:33.488828Z","iopub.status.idle":"2025-04-09T21:50:33.505754Z","shell.execute_reply.started":"2025-04-09T21:50:33.488780Z","shell.execute_reply":"2025-04-09T21:50:33.505035Z"}},"outputs":[],"execution_count":13},{"id":"e9890afd","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9890afd","executionInfo":{"status":"ok","timestamp":1744230055589,"user_tz":-120,"elapsed":8,"user":{"displayName":"Hossam Eldin Abdelrazek","userId":"16974979097625293558"}},"outputId":"669a9f7b-dad9-400f-b2fe-939747217809","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:50:34.337824Z","iopub.execute_input":"2025-04-09T21:50:34.338101Z","iopub.status.idle":"2025-04-09T21:50:34.342865Z","shell.execute_reply.started":"2025-04-09T21:50:34.338081Z","shell.execute_reply":"2025-04-09T21:50:34.341824Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":14},{"id":"21d63755","cell_type":"markdown","source":"# Model","metadata":{"id":"21d63755"}},{"id":"f6a6acf7","cell_type":"code","source":"class VGG(nn.Module):\n    def __init__(self, num_classes=10):\n        super(VGG, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU())\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU())\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU())\n        self.layer6 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU())\n        self.layer7 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer8 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU())\n        self.layer9 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU())\n        self.layer10 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer11 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU())\n        self.layer12 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU())\n        self.layer13 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(7*7*512, 4096),\n            nn.ReLU())\n        self.fc1 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU())\n        self.fc2= nn.Sequential(\n            nn.Linear(4096, num_classes))\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.layer6(x)\n        x = self.layer7(x)\n        x = self.layer8(x)\n        x = self.layer9(x)\n        x = self.layer10(x)\n        x = self.layer11(x)\n        x = self.layer12(x)\n        x = self.layer13(x)\n        x = x.reshape(x.size(0), -1)\n        x = self.fc(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x","metadata":{"id":"f6a6acf7","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:50:35.836008Z","iopub.execute_input":"2025-04-09T21:50:35.836323Z","iopub.status.idle":"2025-04-09T21:50:35.848178Z","shell.execute_reply.started":"2025-04-09T21:50:35.836296Z","shell.execute_reply":"2025-04-09T21:50:35.847274Z"}},"outputs":[],"execution_count":15},{"id":"a6b4c0a5","cell_type":"code","source":"model = VGG(num_classes=num_classes).to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nfrom tqdm import tqdm\nloss_fn = nn.CrossEntropyLoss()","metadata":{"id":"a6b4c0a5","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:54:35.786192Z","iopub.execute_input":"2025-04-09T21:54:35.786515Z","iopub.status.idle":"2025-04-09T21:54:37.085540Z","shell.execute_reply.started":"2025-04-09T21:54:35.786492Z","shell.execute_reply":"2025-04-09T21:54:37.084874Z"}},"outputs":[],"execution_count":22},{"id":"4bfd48ec","cell_type":"code","source":"def train_model(model, optimizer, training_loader, criterion=loss_fn, no_epochs=3):\n    model.train()\n    batches = []\n    losses = []\n    j = 0\n\n    for epoch in range(no_epochs):  # Don't wrap this with tqdm\n        running_loss = 0\n        correct = 0\n        total = 0\n\n        loop = tqdm(enumerate(training_loader), total=len(training_loader), desc=f\"Epoch {epoch+1}/{no_epochs}\")\n\n        for i, (images, labels) in loop:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            # Update tqdm with current metrics\n            loop.set_postfix(loss=loss.item(), accuracy=100 * correct / total)\n\n            if i % 100 == 99:\n                avg_loss = running_loss / 100\n                losses.append(avg_loss)\n                j += i\n                batches.append(j)\n                print(f\"Epoch: {epoch}, Batch: {i+1}, Loss: {avg_loss:.3f}, Accuracy: {100 * correct / total:.2f}%\")\n                running_loss = 0\n\n        if epoch % 2 == 0:\n            print(f\"Epoch {epoch+1} completed\")\n\n    return model, losses, batches\n","metadata":{"id":"4bfd48ec","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:50:38.547476Z","iopub.execute_input":"2025-04-09T21:50:38.547768Z","iopub.status.idle":"2025-04-09T21:50:38.563160Z","shell.execute_reply.started":"2025-04-09T21:50:38.547737Z","shell.execute_reply":"2025-04-09T21:50:38.562345Z"}},"outputs":[],"execution_count":18},{"id":"2a209426","cell_type":"code","source":"def plot_loss(losses, batches):\n    plt.plot(batches, losses)\n    plt.xlabel('Batches')\n    plt.ylabel('Loss')\n    plt.title('Loss vs. Batches')\n    plt.show()","metadata":{"id":"2a209426","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:50:39.175653Z","iopub.execute_input":"2025-04-09T21:50:39.175964Z","iopub.status.idle":"2025-04-09T21:50:39.179958Z","shell.execute_reply.started":"2025-04-09T21:50:39.175941Z","shell.execute_reply":"2025-04-09T21:50:39.179071Z"}},"outputs":[],"execution_count":19},{"id":"554ce2b2","cell_type":"code","source":"model1, losses, batches = train_model(model, optimizer, train_loader, loss_fn, no_epochs=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"554ce2b2","executionInfo":{"status":"ok","timestamp":1744230322117,"user_tz":-120,"elapsed":116557,"user":{"displayName":"Hossam Eldin Abdelrazek","userId":"16974979097625293558"}},"outputId":"53cafd4f-f641-4829-eae6-a36baae8e371","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:50:39.519492Z","iopub.execute_input":"2025-04-09T21:50:39.519774Z","iopub.status.idle":"2025-04-09T21:52:20.975994Z","shell.execute_reply.started":"2025-04-09T21:50:39.519754Z","shell.execute_reply":"2025-04-09T21:52:20.974599Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10:  25%|██▌       | 100/393 [00:27<01:15,  3.87it/s, accuracy=4.44, loss=3.41]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Batch: 100, Loss: 3.441, Accuracy: 4.44%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  51%|█████     | 200/393 [00:53<00:50,  3.80it/s, accuracy=4.31, loss=3.44]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Batch: 200, Loss: 3.432, Accuracy: 4.31%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  76%|███████▋  | 300/393 [01:19<00:24,  3.78it/s, accuracy=4.02, loss=3.44]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Batch: 300, Loss: 3.432, Accuracy: 4.02%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  96%|█████████▋| 379/393 [01:41<00:03,  3.74it/s, accuracy=3.92, loss=3.41]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-848e53a6044e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-8a2a2bc3b304>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, training_loader, criterion, no_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":20},{"id":"d66222fc-1479-4b60-967f-315af4e7239a","cell_type":"markdown","source":"accuracy doesn't change","metadata":{}},{"id":"fae4d42c-f700-43f5-8932-9aba29f2cf59","cell_type":"markdown","source":"# Model 2 with BR","metadata":{}},{"id":"6bf19ee8-4c6c-4b03-adbc-196dea582ec0","cell_type":"code","source":"model2 = VGG16(num)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"07038600-f28c-4f13-b1cf-9aadb8c7aca8","cell_type":"code","source":"class VGG16(nn.Module):\n    def __init__(self, num_classes=10):\n        super(VGG16, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(), \n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU())\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        self.layer6 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        self.layer7 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer8 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer9 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer10 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.layer11 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer12 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        self.layer13 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(7*7*512, 4096),\n            nn.ReLU())\n        self.fc1 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU())\n        self.fc2= nn.Sequential(\n            nn.Linear(4096, num_classes))\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = self.layer6(out)\n        out = self.layer7(out)\n        out = self.layer8(out)\n        out = self.layer9(out)\n        out = self.layer10(out)\n        out = self.layer11(out)\n        out = self.layer12(out)\n        out = self.layer13(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:54:56.769378Z","iopub.execute_input":"2025-04-09T21:54:56.769712Z","iopub.status.idle":"2025-04-09T21:54:56.782744Z","shell.execute_reply.started":"2025-04-09T21:54:56.769683Z","shell.execute_reply":"2025-04-09T21:54:56.781735Z"}},"outputs":[],"execution_count":23},{"id":"f7aeeec1-77f9-4d63-b100-7d768b81e101","cell_type":"code","source":"model2 = VGG16","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4ce19814","cell_type":"code","source":"def evaluate_model(model, loader):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n\n            _, predicted = torch.max(outputs.data, 1)\n\n            total += labels.size(0)\n\n            correct += (predicted == labels).sum().item()\n\n    print(f\"\\nTest Accuracy: {100 * correct / total:.2f}%\")","metadata":{"id":"4ce19814","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:52:20.976639Z","iopub.status.idle":"2025-04-09T21:52:20.976922Z","shell.execute_reply":"2025-04-09T21:52:20.976815Z"}},"outputs":[],"execution_count":null},{"id":"9e21c0f1","cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplot_loss(losses, batches)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"9e21c0f1","executionInfo":{"status":"ok","timestamp":1744230189352,"user_tz":-120,"elapsed":165,"user":{"displayName":"Hossam Eldin Abdelrazek","userId":"16974979097625293558"}},"outputId":"a111ff68-1627-48e6-c9ae-862cd141016f","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:52:20.977765Z","iopub.status.idle":"2025-04-09T21:52:20.978150Z","shell.execute_reply":"2025-04-09T21:52:20.977992Z"}},"outputs":[],"execution_count":null},{"id":"0706ecf3","cell_type":"code","source":"evaluate_model(model1, validation_loader)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0706ecf3","executionInfo":{"status":"ok","timestamp":1744230663762,"user_tz":-120,"elapsed":1241,"user":{"displayName":"Hossam Eldin Abdelrazek","userId":"16974979097625293558"}},"outputId":"eb7d456e-2d1b-4353-b71d-d6b906ebcfaf","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T21:52:20.979112Z","iopub.status.idle":"2025-04-09T21:52:20.979491Z","shell.execute_reply":"2025-04-09T21:52:20.979322Z"}},"outputs":[],"execution_count":null},{"id":"T1GFl-aUQDQA","cell_type":"markdown","source":"Batch Normalization clearly has better results","metadata":{"id":"T1GFl-aUQDQA"}},{"id":"db8c1afa-70cd-454c-86bd-62ace52831d1","cell_type":"markdown","source":"","metadata":{}}]}